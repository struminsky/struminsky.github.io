I am a Ph.D. candidate at [Centre for Deep Learning and Bayesian Methods](https://twitter.com/bayesgroup) at [HSE University](https://cs.hse.ru/en/).Â 

My work focuses on various topics in probabilistic machine learning, such as approximate inference, generative models, and structure learning. I pursue my newly found interest in computer graphics and play table tennis in my spare time.

[Twitter](https://twitter.com/k_struminsky) /
[CV](files/cv.pdf) /
[Google Scholar](https://scholar.google.com/citations?user=q69zIO0AAAAJ) /
[Github](https://github.com/struminsky)

### Selected Publications

- [Leveraging Recursive Gumbel-Max Trick for Approximate Inference in Combinatorial Spaces](https://arxiv.org/abs/2110.15072). Kirill Struminsky*, Artyom Gadetsky*, Denis Rakitin*, Danil Karpushkin, and Dmitry Vetrov. NeurIPS 2021. 
- [Low-Variance Black-Box Gradient Estimates for the Plackett-Luce Distribution](https://arxiv.org/abs/1911.10036). Artyom Gadetsky*, Kirill Struminsky*, Christopher Robinson, Novi Quadrianto, and Dmitry Vetroc. AAAI 2020.
- [The Deep Weight Prior. Modeling a Prior Distribution for CNNs Using Generative Models](https://arxiv.org/abs/1810.06943). Andrey Atanov*, Senya Ashukha*, Kirill Strumisnky, Dmitry Vetrov, and Max Welling. ICLR 2019.
- [Quantifying Learning Guarantees for Convex but Inconsistent Surrogates](https://arxiv.org/abs/1810.11544). Kirill Struminsky, Simone Lacoste-Julien, and Anton Osokin. NeurIPS 2018.
